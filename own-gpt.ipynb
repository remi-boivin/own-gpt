{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/remi-boivin/own-gpt/blob/google_colab/own-gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "block_size = 8\n",
        "batch_size = 4\n",
        "learning_rate = 3e-4\n",
        "max_iters = 10000\n",
        "eval_iters = 250\n",
        "dropout=0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT_e0hY3ieUs",
        "outputId": "071b64b5-c2c2-46ba-a2a7-d81fb11f10cd"
      },
      "id": "mT_e0hY3ieUs",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "wocabulary"
      ],
      "metadata": {
        "id": "CrJR3LRoYys9"
      },
      "id": "CrJR3LRoYys9"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UibUwPOTibw6"
      },
      "id": "UibUwPOTibw6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "ccc2e4f0-39f6-461e-a628-84cf098551e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccc2e4f0-39f6-461e-a628-84cf098551e3",
        "outputId": "bf133fc6-8cf4-42c1-d947-b984199bace3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ', '!', '\"', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}', '·', '\\ufeff']\n"
          ]
        }
      ],
      "source": [
        "with open(\"wizard_of_oz.txt\", encoding=\"utf-8\") as f:\n",
        "  text = f.read()\n",
        "chars = sorted(set(text))\n",
        "print(chars)\n",
        "vocab_size = len(chars)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "encoder"
      ],
      "metadata": {
        "id": "LCSRkOo6Y7_Y"
      },
      "id": "LCSRkOo6Y7_Y"
    },
    {
      "cell_type": "code",
      "source": [
        "string_to_int = { ch:i for i,ch in enumerate(chars)}\n",
        "int_to_string = { i:ch for i,ch in enumerate(chars)}\n",
        "encode = lambda s: [string_to_int[c] for c in s]\n",
        "decode = lambda l: ''.join(int_to_string[i] for i in l)\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data[:100])"
      ],
      "metadata": {
        "id": "3Z-WASthZDYP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b717d808-7658-4f7a-fb1b-06a04e49ac58"
      },
      "id": "3Z-WASthZDYP",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([83,  2, 72, 57, 81, 68, 71, 57, 60,  2, 23, 83,  2, 57, 68, 68, 45, 64,\n",
            "        71, 74, 76, 59, 77, 76, 75, 31, 70, 57, 58, 68, 61, 60,  2, 23, 62, 57,\n",
            "        68, 75, 61,  9,  2, 62, 65, 68, 61, 46, 74, 61, 61,  2, 23, 83,  2,  2,\n",
            "        23, 83,  2, 65, 76, 61, 69, 75,  2, 23, 53, 83,  2, 70, 57, 69, 61,  2,\n",
            "        23,  2, 44, 31, 27, 30, 39, 31, 11, 69, 60,  2,  9,  2, 72, 57, 76, 64,\n",
            "         2, 23,  2, 44, 31, 27, 30, 39, 31, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.8 * len(data))\n",
        "train_data = data[:n]\n",
        "valid_data = data[n:]\n",
        "\n",
        "def get_batch(split):\n",
        "  data = train_data if split == 'train' else val_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
        "#  print(ix)\n",
        "  x = torch.stack([data[i:i + block_size] for i in ix])\n",
        "  y = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  return x,y\n",
        "\n",
        "x,y = get_batch('train')\n",
        "print(f\"inputs: {x}\\n targets {y}\")"
      ],
      "metadata": {
        "id": "X-CU7ngeZr1c",
        "outputId": "a74ccf6b-0113-4e53-a9f4-0388078774bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "X-CU7ngeZr1c",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs: tensor([[58, 77, 76,  0, 75, 64, 61,  0],\n",
            "        [64, 61,  0, 64, 57, 68, 68,  0],\n",
            "        [65, 76,  0, 69, 77, 75, 76,  0],\n",
            "        [54, 74,  2,  9,  2, 64, 61, 57]])\n",
            " targets tensor([[77, 76,  0, 75, 64, 61,  0, 59],\n",
            "        [61,  0, 64, 57, 68, 68,  0, 57],\n",
            "        [76,  0, 69, 77, 75, 76,  0, 64],\n",
            "        [74,  2,  9,  2, 64, 61, 57, 60]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  out = {}\n",
        "  model.eval()\n",
        "  for split in['train', 'val']:\n",
        "    losses = torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      X, Y = get_batch(split)\n",
        "      logits, loss = model(X, Y)\n",
        "      losses[k] = loss.item()\n",
        "      out[split] = losses.mean()\n",
        "  model.train()\n",
        "  return out"
      ],
      "metadata": {
        "id": "G2mOrIftHTuC"
      },
      "id": "G2mOrIftHTuC",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "  def forward(self, index, targets=None):\n",
        "    logits = self.token_embedding_table(index)\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(B*T, C)\n",
        "      targets = targets.view(B * T)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, index, max_new_token):\n",
        "    # index is (B, T) array of indices in the current context\n",
        "    for _ in range(max_new_token):\n",
        "      # get the predictions\n",
        "      logits, loss = self.forward(index)\n",
        "      # focus only on the latest time step\n",
        "      logits = logits[:, -1, :] # become (B, C)\n",
        "      #apply softmax to get probabilities\n",
        "      probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "      # sample from the distribution\n",
        "      index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "      # append sampled index to the running sequence\n",
        "      index = torch.cat((index, index_next), dim= 1) # (B, T + 1)\n",
        "    return index\n",
        "\n",
        "model = BigramLanguageModel(vocab_size)\n",
        "m = model.to(device)\n",
        "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "generated_chars = decode(m.generate(context, max_new_token=3500)[0].tolist())\n",
        "print(generated_chars)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afdwFFRMJgT3",
        "outputId": "5048013f-f7d3-44fd-a998-9b3017e3e4fd"
      },
      "id": "afdwFFRMJgT3",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -vbfo(FEO8[qly9&k7y\"·Ag3YD5;l]LBbdg Zvb-* &aUm4E·f1G]B]!=40pO·diZMaCxI40rM' DJA&4Gm(X5k_4BC/d%mpeT;K2uu)nQ)ZN1GR{P:QRvuf5kFS1P//R:T8kF .eSReTLcjs?,PP﻿p.S·Fcuo·r62%/3\\[nrC'S%(3Vgu?4e]yMzT:[﻿!8QCg)5p&XoOhN rC46veK2J8?'pLJVCx{GuHJ%[)el!\\I(X(a﻿)4Jtfx{2,\"yE·LT=C*\"we3NHqp\"vuDFygdgkfvm*QC*AVl4'V9·o]\"]:y9Tw,iZ!S5Jw,)5N]L4nWbVJ\\JA&f-1FEmO!8Es('RKrDVJ3Yh4J81L\\41/rDFlxI\"iZO7HgOLT(}X:d[\"l]y9Tk*Ac.6,Gy9m&p3\\}nij?EW24DZ)0LY/%5ZYBNm=B6rvp?JAhnPa\\yG'5h4_z6vgodJ4·oq,%qK;GG'bW=MEs]7P0coWBCU'}S﻿?AsvOnQ](vee}orCV7X83ax{Knv!u:TNBfm=Z:rYnbiCS]NAL{M2XCx[)l/dVymFVG-Ef77C'GlLAX(J8Qof%5aj %-,pc-Y2;61L*KpCRkdpUgDZ-5J6T)k:FY7zabYSYYdvfafjgTNTvS4z)kH2:Ff1kbMfL.\\?J3*ZO!\\kzR_;?\"*)9utw D﻿pdxK;5MBNAV%[3YH7tOq[=\\Zvz H&fDluY_0p·tO[(CEbVk7])9iu_y(sz5*WEd=Yky'WgtjMjaOL*ME!/nQ)93\\4i{PLjb'RmO0*I6v!]LXM&\\oM]Q.nv!WPakH﻿8y94]y2:q6J-mniLDRSa9EC*gaO!8IO\\,[G'O!h%-U\"E({gtltw\"CabAgD?T:-3x)·gFcr.[ICy=um!8U5=R9S﻿pW3l&%qwcDS﻿nopIbk_W [6&O_MJA)U;zVQ)7xsaoZM/F}Me5h))oj\"} %/Q;gEeS4_jC/d'fvbgxm&f4KtGP{;-j3'%RBAC)'Zw?X4DV74YK\"[=48f=9!k,LwgC*WRK0c.wwNCdY:*.p6N\\G0(X}5·A]3;PX'%6Ot=opekjC%1/i·f3'nC4KPm1*AEvS42{PCp\\/S{lcub}}lvz{f4kpG-7uo·JAEToTELyu8k1[YdgA]f*BsB?0Q):T:;!xIAH?PKlht&*.0Tzc!k_i7x T﻿&?AT:dYe0.tOFw]8MHx.Qh*[:dgU_Y!uVb':7uF75(I7w8AYnS] %1IHx}?﻿/JI\"H7fB__\"91j)kJA9=oCB7tO!W5k_dEH?Z/Wj7,7qzCp)E7&fGACKkFG%eReSS6,fDPbmLyH\"Zu6EG_An=4_UZQkZ/Kvd wzd!f[{Z7L=hN;:J4,YxhA]QD\"-pDr(X&GsJEeex/dJ\\,7bZ/rU*r3FNQ%qxKxR\\;-YgT_KXhN iZOhMk]?&Za{WY7WgCDDFNC2&ZE!k:G'%[MK1[\\B8Gvbc;iZ'O;D2.Dyu[kd;Z2gC\\0Kn.3'Kz %\\o8IdRB{PL4G-Q]m(ZM]M4tOZf&F﻿!hnnFXM7'\"0*[﻿;-VD92i* 2{RoXUiZY8(3WD2JbkWGblY{U([G\"FhhNVfjx{P]8L%S]U:h!nu8ro'R:rr,2Cni\"oc'%Okl%q,6Q9;[%-UT{YU_ZfT:{cO7H2C\\%AZ?BCI0QWYHRPj }T:/dE8(XUVQBLXoCjzc!\\[w7L2(X%NEPil1j/Bq3lO!Ab]yHycxsRnJ\"oL-l Cp[u5):{PZOG';acrDV3)=[ u&o5J8hsRPrMD1[ =xxtrQkea:Fy/]Bco89\"9zR[02g /83&5a·/iZJthml*I9eSifC12C·:34,9OqtH﻿pI m}{!O qcnDV1kFG\\ISH!O﻿gtVFO5D'ThXdI%TM?hAn\"C[xa0TP:diH83=xEG-lUCV}.e2;qz4Y{\\01T_g8Lw·YJ8LVHY/o·Les4﻿jX&]yd%=j.:dRUx{Y{wR:a﻿=JXJ·f=9JP{_Kpl}qQ5_.1/Q}cil*HxEV]qo&o;ut:&O,E;K9_'J(}j7Z!P_AQ9_!=\\j2h_{yCgEeS﻿;-vx)7qNvCvbnRL5EO!{W0}69X6Koph﻿E!PiZ-sC*qwIPr.(,dIT=YP]Pq*koZq}nzC1?_[x/R6x9XJPk-NB}*!\"-I}d Pke})t'%6*NWR_0r_068L4﻿!\\Vzlxt&ZKmlG('\"Cti%JLpL{P:Py9]\\BCEL{PTMcOQU7oZOC&(KrDT=9*[']V\\,S(,!mlt)9M4X(XMk,83\\Iy9grDVFS=?]N4UQ ?&!lnvEIP6}dJ6vLepMkN1]Bb,Stk﻿}3Um [{-8z7CNGNXMQ0d9eSJ4OttHZFyQ59E!WD9=Yut5d?PhELynpD\"5}uf=y9tOiX?hNXVMQ﻿po&oZxwz6\\WAQVVRwNLRnU_q\\kpVdI(vbu;gt4XE\"*9q&fL4)IdZ9v&Z58I1jMe*HJv!*(,*[Y0cG93\\yMsA&t[ [xDJd}uuYg}s]!lnCCu-TD%Uj(Ft ?'T)72CpRVR{4&& ?Y·{﻿pCVVDTcEV/&ZF9A.[Gsz=k7I1Yy/l&!WUfokC\\zerqLH﻿p2uHT T\"Cxt9_}!8ohy?:D5qlMHY7,]8z6pnhs/D%3AcXUcT,=Y30Kq,eT=iZMFiZWcdiZx·NQ8L7XoZuqqzt22Q/ DZ{Pj3=M'oMfPY\"XH/r4AZ%q{!\\dd\"5koYKNv0nd[CErFo﻿[o·FN4\\2v(5k:z;QyV[ JMqp\"C*0rbd;6rOtmj'iTBzrR'%\\bItOK?nIcR.Vqz6_WE9M=R&f=RRAxj':TDVV78t2CS4MnrD9j6&MJhY4-y1jhx*WH]j7Z?q;T='&M0u3\\gdJ=G,ZKC*a*\\4!z_S!tw'q6pz,KC5E4tMuhE]_{* Yzv0*Sz'Qju-ut&fi'[FEY,utFMXhTfT﻿q.e_kdA]\\-69]Ldg3XYg3'xE2J2(﻿t6vbFX %s1/rq,7P:/AcT=1(XU5vBN;5pGCop_*Ico(}NMQ;·_jm}Y'jbM5R/rDVf.Z3=o6;k'diTc.eS_o·tNX&QxapVVV)U[GhBC/?hNDpO,P{P]%?8f8W1/?A2Jh%Rf{K*u\\g_K1/&86vj6rnV7q,L-6·{aQpPaQ8wH2x{qlyn3o]&p07o; NdAVDt10)_az6vf\"Z:y0w&2vLDJhm7sjbpR1D\"FV(3417ltG)Z9Oc=Lc2h.{Pa2)7] AE ?Wvb,EvIc_}.,7qp=oplc=o;buHaDsYg8tj6Odz)=5\"ELJ4FyZOUfnQLy9EdPX}7PaoI0*IjU5:vg)sz56-T!3aG-Yq(lyze29}V7d9=K·}diHhVBC77?51kgU{Hto:TzrDU&3O﻿03}!z64nCtAVQiZ%!.4i]tOZMAj_b_*[\\oMqDZ/NgJyX_aB;fUD\"H2T]{PakL Z\\p\"XoT(kBK0p?fH4﻿﻿p?03edxV7Fy'*6rFE/ZO5\\ceS]9qX4US].ZYWC?&fwR?vb,CEbwPp)5kh0Obi]cR[&QVi5jbjoCp/XYcz1D5\"5NWgakZ/.﻿V7\"TuzoeSZxDZMqL4f(ailt*],=R\"roC8RvDhxIdgEbilgDO!ZJRVY'T﻿p\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#x = train_data[:block_size]\n",
        "#y = train_data[1:block_size + 1]\n",
        "\n",
        "#for t in range(block_size):\n",
        "#  context = x[:t + 1]\n",
        "#  target = y[t]\n",
        "#  print('when input is', context, 'target is', target)\n",
        "import time\n",
        "started_time = time.time()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "for iter in range(max_iters):\n",
        "  if iter % eval_{iters}\n",
        "    print(f\"step: {iter}, loss: {losses}\")\n",
        "  xb, yb = get_batch('train')\n",
        "\n",
        "  logits, loss = model.forward(xb, yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "end_time = time.time()\n",
        "print(f\"time of training: {end_time - started_time}\\nloss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQoormeFlR1J",
        "outputId": "6377b2af-a732-490e-e768-0a399bffa387"
      },
      "id": "eQoormeFlR1J",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time of training: 8.57400369644165\n",
            "loss: 2.815788984298706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ntXM0RCA5Elr"
      },
      "id": "ntXM0RCA5Elr",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}